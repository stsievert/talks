{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda3/lib/python3.6/site-packages/distributed/bokeh/core.py:74: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:58951\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:58952/status' target='_blank'>http://127.0.0.1:58952/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.59 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:58951' processes=4 cores=4>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import noisy_mnist\n",
    "# chunk_size = 70_000 // 3\n",
    "# _X, _y = noisy_mnist.dataset()\n",
    "# X = _X[:chunk_size * 3]\n",
    "# y = _y[:chunk_size * 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "# n, d = _X.shape\n",
    "# X = da.from_array(_X, chunks=(n // 3, d))\n",
    "# y = da.from_array(_y, chunks=n // 3)\n",
    "# X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import Autoencoder, NegLossScore\n",
    "import torch\n",
    "# from sklearn.model_selection import ParameterSampler\n",
    "import torch\n",
    "\n",
    "def trim_params(**kwargs):\n",
    "    if kwargs['optimizer'] != 'Adam':\n",
    "        kwargs.pop('optimizer__amsgrad', None)\n",
    "    if kwargs['optimizer'] == 'Adam':\n",
    "        kwargs.pop('optimizer__lr', None)\n",
    "    if kwargs['optimizer'] != 'SGD':\n",
    "        kwargs.pop('optimizer__nesterov', None)\n",
    "        kwargs.pop('optimizer__momentum', None)\n",
    "    kwargs['optimizer'] = getattr(torch.optim, kwargs['optimizer'])\n",
    "    return kwargs\n",
    "\n",
    "class TrimParams(NegLossScore):\n",
    "    def set_params(self, **kwargs):\n",
    "        kwargs = trim_params(**kwargs)\n",
    "        return super().set_params(**kwargs)\n",
    "\n",
    "model = TrimParams(\n",
    "    module=Autoencoder,\n",
    "    criterion=torch.nn.BCELoss,\n",
    "    warm_start=True,\n",
    "    train_split=None,\n",
    "    max_epochs=1,\n",
    "    callbacks=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "    'module__init': ['xavier_uniform_',\n",
    "                     'xavier_normal_',\n",
    "                     'kaiming_uniform_',\n",
    "                     'kaiming_normal_',\n",
    "                    ],\n",
    "    'module__activation': ['ReLU', 'LeakyReLU', 'ELU', 'PReLU'],\n",
    "    'optimizer': [\"SGD\"] * 5 + [\"Adam\"] * 2,\n",
    "    'batch_size': [32, 64, 128, 256, 512],\n",
    "    'optimizer__lr': np.logspace(1, -1.5, num=1000),\n",
    "    'optimizer__weight_decay': [0]*200 + np.logspace(-5, -3, num=1000).tolist(),\n",
    "    'optimizer__nesterov': [True],\n",
    "    'optimizer__momentum': np.linspace(0, 1, num=1000),\n",
    "    'train_split': [None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class '__main__.TrimParams'>[uninitialized](\n",
       "  module=<class 'autoencoder.Autoencoder'>,\n",
       "  module_=Autoencoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=784, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Linear(in_features=784, out_features=196, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=196, out_features=784, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Linear(in_features=784, out_features=784, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "  ),\n",
       "  module__activation=LeakyReLU,\n",
       "  module__init=kaiming_uniform_,\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "param = list(ParameterSampler(params, 4, random_state=3))[0]\n",
    "\n",
    "model.set_params(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
